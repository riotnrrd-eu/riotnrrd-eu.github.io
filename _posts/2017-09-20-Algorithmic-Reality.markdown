---
layout: post
title:  Algorithmic Reality 
date:   2017-09-20 
categories:  matrix AI 
---

# Algorithmic Reality


What if all of those earnest post-*Matrix* philosophical discussions were more on point than we knew? 

One of the central conceits of the *Matrix* films is that the machines simulate  a late-twentieth-century environment for their human “batteries”…

Oh. Spoiler warning, I guess? Do we still need that for a film that came out in 1999? I’m calling it - anything from last century is now fair game.

As we were: all the humans live in a simulated late-90s world, complete with all sorts of weird and wonderful mobile phones, before we decided collectively that all phones should look like smooth rectangles of black glass.

![|751x0](/images/unknown_filename.17.png)

This of course had nothing whatsoever to do with the fact that the late 90s were contemporaneous with when the films were being made, and therefore cheap to film, and everything to do with the late 90s apparently being recognised as the pinnacle of human civilisation. 

Here’s the thing: ***what if the Wachowskis were right?***

The twenty-first century is no longer the domain of a purely *human* civilisation. We are now a hybrid, cyborg civilisation, where baseline humans are augmented by artificial systems. I don’t think we are heading towards a *Matrix*-style takeover by the machines, but this is going to be a significant change, and one that is hard to fully comprehend from the inside, while it is happening. Also, once the change has happened, what came before will be *fundamentally incomprehensible* to anyone who comes of age in that future world.

The world they will inhabit will have bots and algorithms the way we baseline humans today have commensal bacteria in our guts. Our guts have [enormous structures of neurons](https://www.scientificamerican.com/article/gut-feelings-the-second-brain-in-our-gastrointestinal-systems-excerpt/ "Gut Feelings–the "Second Brain" in Our Gastrointestinal Systems" ), second only to the brain itself:

> Why is our gut the only organ in our body that needs its own "brain"? Is it just to manage the process of digestion? Or could it be that one job of our second brain is to listen in on the trillions of microbes residing in the gut?

Algorithms will begin to take part in this process too, as more and more of our cognition occurs outside our own biological minds. These off-board exo-selves will feel as much a part of us as our “gut feel” does today, but they will fundamentally change what it means - and how it feels - to be human.

We can see the beginnings of this process already: we drive where the algorithms tell us to drive, we exercise the way the algorithms tell us to exercise, and we even date whom the algorithms tell us to date. We buy films, music, and books that the algorithms recommend, go on holiday where they suggest, and take jobs that they set us up with. In the future, what other decisions will we hand over to algorithms - unquestioning and unconcerned?

The algorithms and bots may not be out to enslave us, but they do see things dramatically differently than we do. For an example, take a look at this map: 

![|2048x0](/images/IMG_0171.JPG)

This is a snapshot of a map of the continental US doing the recent solar eclipse. The traffic algorithm has no idea of what an eclipse is, but it does know that something weird is happening: people are stopping their cars in the middle of roads across a wide strip of the US.

Famously, [an algorithm figured out a teenage girl was pregnant before her dad did](https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/ "How Target Figured Out A Teen Girl Was Pregnant Before Her Father Did?" ):

> An angry man went into a Target outside of Minneapolis, demanding to talk to a manager:
> "My daughter got this in the mail!" he said. "She’s still in high school, and you’re sending her coupons for baby clothes and cribs? Are you trying to encourage her to get pregnant?"
> The manager didn’t have any idea what the man was talking about. He looked at the mailer. Sure enough, it was addressed to the man’s daughter and contained advertisements for maternity clothing, nursery furniture and pictures of smiling infants. The manager apologized and then called a few days later to apologize again.
> On the phone, though, the father was somewhat abashed. "I had a talk with my daughter," he said. "It turns out there’s been some activities in my house I haven’t been completely aware of. She’s due in August. I owe you an apology."

And that’s not even the creepiest thing algorithms can do. They can [identify your face, even when you hide it with a scarf to go to a protest](https://motherboard.vice.com/en_us/article/mbby88/ai-will-soon-identify-protesters-with-their-faces-partly-concealed "AI Will Soon Identify Protesters With Their Faces Partly Concealed" ) - (unless of course [they can’t](https://www.liberty-human-rights.org.uk/news/blog/misidentification-and-improvised-rules-we-lift-lid-mets-notting-hill-facial-recognition "Misidentification and improvised rules - we lift the lid on the Met's Notting Hill facial recognition operation" ) ), and they can [tell your sexual orientation from a photograph](https://www.theguardian.com/technology/2017/sep/07/new-artificial-intelligence-can-tell-whether-youre-gay-or-straight-from-a-photograph "New AI can guess whether you're gay or straight from a photograph" ).

This is why DRM, privacy, and user control in general are such important topics: we are talking about our own future exoselves here. There are perfectly legitimate reasons not to want to broadcast your identity and all your particulars to all and sundry, especially in a world which is unfortunately still filled with prejudices against anyone who doesn’t fit in with the majority. And if something that is guiding your actions and your very *thoughts* belongs to a corporation that makes money from people who want to influence your actions and your thoughts, where does that leave you? About as enslaved as those human batteries in the *Matrix*, I’d say.

![|751x0](/images/unknown_filename.18.jpeg)

I’m a straight white middle-class dude, cis-het or whatever, and basically so square I’m practically cubic, so all of this is very far from affecting me personally. I’m at the very bottom of [Niemöller’s poem](https://en.wikipedia.org/wiki/First_they_came_… "First they came ...” ) - but I have friends and relatives who are much higher up, so I have both personal and selfish reasons for wanting to make sure this is done right. Personal, because don’t mess with my friends, and selfish, because as the Reverend Martin wrote, if we don’t fix it early, by the time it gets to causing problems for me, it will be way too late to do anything about it.

And of course there are all sorts of other aspects of this new future that we are building which all too few people are thinking about. Future historians will refer to these decades as ["Digital Dark Ages"](http://www.antipope.org/charlie/blog-static/2009/01/dark_ages_start_here.html "Preventing the New Dark Ages: Start Here" ): our history will be lost behind gratuitously incompatible file formats and DRM to which no living entity (human or corporate) has the keys any more. I was able to flip through my grandparents’ pictures and read a great-uncle’s book; as things stand, my grandchildren will not be able to have this experience.

The late twentieth century may indeed go down as the high-water mark of the purely human civilisation. The technologies that would make up the new world already existed - I played a full VR game, with goggles, 3D mouse, and a subwoofer in a backpack rig, in 1998 - but they were not yet fully joined up, and only vanishingly few people appreciated what would happen when they would all be connected up.

I have no intention of standing athwart history, yelling *Stop* - but we do need to think carefully about what kind of future we are building, and where it will take us. If the first couple of decades of this scary new century have taught us anything, it’s that the defences of “oh, that’ll never work” and “nobody would ever do that” are no defence at all, in cryptology, civil liberties, or anywhere else - if, indeed, they ever were.

